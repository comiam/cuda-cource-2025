### Как скомпилировать и запустить

```bash
nvcc matrix_mul.cu -o matrix_mul -O3
./matrix_mul
```

### Пояснение реализации

#### 1. Naive Implementation (Наивная версия)
В наивной реализации каждый тред вычисляет один элемент результирующей матрицы $C$. Для этого он проходит циклом по $K$. Один тред выполняет много глобальных чтений памяти и операций с плавающей точкой. Много раз треды читают одну и ту же память.

#### 2. Optimized Implementation (Shared Memory / Tiling)
1.  Матрицы разбиваются на тайлы и кладутся в Shared Memory
2.  Каждый блок вычисляет квадратный подматрицу размером TILE_SIZE x TILE_SIZE.
3.  По ступеьпкам считаем:
    *   Загружаем тайл из матрицы $A$ и тайл из матрицы $B$ в sm
    *   Синхронизируемся, чтоб не было гонок на чтение
    *   Вычисляем частичную сумму, используя только что загруженный в sm кусочки
    *   Синхронизируемся, чтоб не было гонок между итерациями

### Результаты

При размере матрицы 2048x2048:

*   CPU: 5 сек
*   GPU Naive: 0.10 сек
*   GPU Shared: 0.02 сек

В коде используются костыли `if (row < M) и if (col < N)`. При загрузке тайлов за границами матрицы, мы записываем в sm 0, чтоб вычисления не сломались и не влияли на результат.
Доступ к глобальной памяти в коде организован так, что соседние треды (по tx) читают соседние ячейки памяти (coalesce).
