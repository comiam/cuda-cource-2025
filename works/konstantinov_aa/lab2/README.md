# Lab 2: Matrix Multiplication - Перемножение матриц

## Описание
Реализация перемножения матриц на CUDA с использованием разделяемой памяти (shared memory) для оптимизации доступа к глобальной памяти.
Поддерживается умножение матриц произвольного размера (MxK * KxN = MxN).


## Использование
Программа запросит размерности матриц M, K, N.
- Матрица A имеет размер MxK
- Матрица B имеет размер KxN
- Результирующая матрица C будет иметь размер MxN

Пример ввода:
```
Enter matrix sizes M K N (A: MxK, B: KxN): 16 16 16
```

## Алгоритм
Используется блочное перемножение (tiled multiplication) с размером блока 16x16.
Каждый блок потоков загружает подматрицы A и B в shared memory, выполняет вычисления и переходит к следующему тайлу.

## Результаты производительности
Тестирование проводилось на квадратных матрицах разного размера.
**Сборка производилась напрямую через `nvcc`** (из-за проблем CMake с кириллицей в путях).

| Размер матрицы (NxN) | GPU Время (ms) | CPU Время (ms) | Ускорение (Speedup) |
|----------------------|----------------|----------------|---------------------|
| 64x64                | 0.80           | 0.96           | **1.2x**            |
| 128x128              | 0.44           | 6.13           | **13.8x**           |
| 256x256              | 0.64           | 47.44          | **73.9x**           |
| 512x512              | 1.24           | 439.98         | **354.8x**          |

**Вывод:**
На малых размерах (64x64) накладные расходы на копирование памяти и запуск ядра сопоставимы с временем вычислений.
Однако уже на размере 512x512 GPU показывает колоссальное преимущество (более 350 раз), что подтверждает эффективность параллельных вычислений для матричных операций.
Использование Shared Memory позволяет минимизировать доступ к медленной глобальной памяти.



